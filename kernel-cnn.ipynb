{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train.csv', 'test.csv', 'embeddings']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "X_train = train_df[\"question_text\"].fillna(\"_na_\").values\n",
    "test_df = pd.read_csv(\"../input/test.csv\")\n",
    "X_test = test_df[\"question_text\"].fillna(\"_na_\").values\n",
    "y = train_df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "8d9a43073037fec13da868e5d5ac8da67b0fd75a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "3bf01e2c2fcd060f410689f4a72ef280d2eaa0e1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, Dropout, SpatialDropout1D\n",
    "from keras.layers import CuDNNGRU, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D, GlobalMaxPool1D\n",
    "from keras.layers import Reshape, Flatten, Concatenate, Conv2D, MaxPool2D\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "b5b0369b0fb3f64bae41549d3055083c266cd592"
   },
   "outputs": [],
   "source": [
    "maxlen = 150\n",
    "max_features = 50000\n",
    "\n",
    "tokenizer = text.Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(X_train) + list(X_test))\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "x_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(X_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "e52674261b7555bcd3985bcb70e5a7a9e2c31830"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 48, 6692, 7163, 158, 55, 5999, 36, 4, 1207, 6, 1, 8262]\n"
     ]
    }
   ],
   "source": [
    "print (X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "bb36c86f44debf58686e64675f3aefc5bd1c01e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    9   48 6692\n",
      " 7163  158   55 5999   36    4 1207    6    1 8262]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "66fce61c783f96a8954491e53303dfd456528763"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_tra, X_val, y_tra, y_val = train_test_split(x_train, y, test_size = 0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "60338bb10efd60f34e34e2bca3f2e7f8d24eedfe"
   },
   "outputs": [],
   "source": [
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "def get_embedding_matrix(embedding_file):\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(embedding_file, encoding=\"utf8\", errors='ignore') if len(o)>100)\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "    word_index = tokenizer.word_index\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix\n",
    "\n",
    "def get_word2vac_matrix(word2vac_file, embed_size = 300):\n",
    "    embeddings_index = KeyedVectors.load_word2vec_format(word2vac_file, binary=True)\n",
    "    word_index = tokenizer.word_index\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    embedding_matrix = (np.random.rand(nb_words, embed_size) - 0.5) / 5.0\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features: continue\n",
    "        if word in embeddings_index:\n",
    "            embedding_vector = embeddings_index.get_vector(word)\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f1cfb75e796f4bf16b67a45413c168ffb3c8a307"
   },
   "source": [
    "%%time\n",
    "EMBEDDING_FILE1 = '../input/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
    "embedding1 = get_embedding_matrix(EMBEDDING_FILE1)\n",
    "print (EMBEDDING_FILE1, embedding1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e658283f134c461641a979b8ede4125a305ab1e8"
   },
   "source": [
    "%%time\n",
    "EMBEDDING_FILE2 = '../input/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "embedding2 = get_embedding_matrix(EMBEDDING_FILE2)\n",
    "print (EMBEDDING_FILE2, embedding2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ce756af80bab89b0b477649a1893a88c0c993769"
   },
   "source": [
    "%%time\n",
    "EMBEDDING_FILE3 = '../input/embeddings/paragram_300_sl999/paragram_300_sl999.txt'\n",
    "embedding3 = get_embedding_matrix(EMBEDDING_FILE3)\n",
    "print (EMBEDDING_FILE3, embedding3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7154f017595f291d318afb0f57c78130b222f022"
   },
   "source": [
    "%%time\n",
    "EMBEDDING_FILE4 = '../input/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin'\n",
    "embedding4 = get_word2vac_matrix(EMBEDDING_FILE4)\n",
    "print (EMBEDDING_FILE4, embedding4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec (50000, 300)\n",
      "../input/embeddings/glove.840B.300d/glove.840B.300d.txt (50000, 300)\n",
      "../input/embeddings/paragram_300_sl999/paragram_300_sl999.txt (50000, 300)\n",
      "../input/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin (50000, 300)\n",
      "CPU times: user 201 ms, sys: 677 ms, total: 878 ms\n",
      "Wall time: 2min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "EMBEDDING_FILE1 = '../input/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
    "EMBEDDING_FILE2 = '../input/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "EMBEDDING_FILE3 = '../input/embeddings/paragram_300_sl999/paragram_300_sl999.txt'\n",
    "EMBEDDING_FILE4 = '../input/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin'\n",
    "\n",
    "pool = Pool()\n",
    "result1 = pool.apply_async(get_embedding_matrix, [EMBEDDING_FILE1]) # evaluate \"solve1(A)\" asynchronously\n",
    "result2 = pool.apply_async(get_embedding_matrix, [EMBEDDING_FILE2]) # evaluate \"solve1(A)\" asynchronously\n",
    "result3 = pool.apply_async(get_embedding_matrix, [EMBEDDING_FILE3]) # evaluate \"solve1(A)\" asynchronously\n",
    "result4 = pool.apply_async(get_word2vac_matrix, [EMBEDDING_FILE4]) # evaluate \"solve1(A)\" asynchronously\n",
    "\n",
    "embedding1 = result1.get(timeout=600)\n",
    "embedding2 = result2.get(timeout=600)\n",
    "embedding3 = result3.get(timeout=600)\n",
    "embedding4 = result4.get(timeout=600)\n",
    "\n",
    "print (EMBEDDING_FILE1, embedding1.shape)\n",
    "print (EMBEDDING_FILE2, embedding2.shape)\n",
    "print (EMBEDDING_FILE3, embedding3.shape)\n",
    "print (EMBEDDING_FILE4, embedding4.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "3808952ff834ffaadd781f0e29fe55b79a77f0d5"
   },
   "outputs": [],
   "source": [
    "class F1Evaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            y_pred = (y_pred > threshold).astype(int)\n",
    "            score = metrics.f1_score(self.y_val, y_pred)\n",
    "            print(\"\\n F1 Score - epoch: %d - score: %.6f \\n\" % (epoch+1, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "89cff668b5bc2d4c74225a57c881e0981d14a948"
   },
   "outputs": [],
   "source": [
    "filter_sizes = [1,2,3,5]\n",
    "num_filters = 42\n",
    "\n",
    "def get_model(embedding_matrix):\n",
    "    embed_size = embedding_matrix.shape[1]\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "#    x = SpatialDropout1D(0.4)(x)\n",
    "    x = Reshape((maxlen, embed_size, 1))(x)\n",
    "    \n",
    "    conv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], embed_size),\n",
    "                                 kernel_initializer='he_normal', activation='tanh')(x)\n",
    "    conv_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], embed_size),\n",
    "                                 kernel_initializer='he_normal', activation='tanh')(x)\n",
    "    conv_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], embed_size), \n",
    "                                 kernel_initializer='he_normal', activation='tanh')(x)\n",
    "    conv_3 = Conv2D(num_filters, kernel_size=(filter_sizes[3], embed_size),\n",
    "                                 kernel_initializer='he_normal', activation='tanh')(x)\n",
    "    \n",
    "    maxpool_0 = MaxPool2D(pool_size=(maxlen - filter_sizes[0] + 1, 1))(conv_0)\n",
    "    maxpool_1 = MaxPool2D(pool_size=(maxlen - filter_sizes[1] + 1, 1))(conv_1)\n",
    "    maxpool_2 = MaxPool2D(pool_size=(maxlen - filter_sizes[2] + 1, 1))(conv_2)\n",
    "    maxpool_3 = MaxPool2D(pool_size=(maxlen - filter_sizes[3] + 1, 1))(conv_3)\n",
    "        \n",
    "    z = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2, maxpool_3])   \n",
    "    z = Flatten()(z)\n",
    "    z = Dropout(0.1)(z)\n",
    "        \n",
    "    outp = Dense(1, activation=\"sigmoid\")(z)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "05977f6446689b95afdd4c471042b3515b628c64"
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.concatenate((embedding1, embedding2, embedding3, embedding4), axis=1)\n",
    "\n",
    "model = get_model(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "72380745e009bb0cb122435d8d709d1404f9efa4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1175509 samples, validate on 130613 samples\n",
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16 #256\n",
    "epochs = 2\n",
    "\n",
    "F1_Score = F1Evaluation(validation_data=(X_val, y_val), interval=1)\n",
    "hist = model.fit(X_tra, y_tra, batch_size=batch_size, epochs=epochs,\n",
    "                 validation_data=(X_val, y_val),\n",
    "                 callbacks=[F1_Score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3b1ddde7338a374043fc5d6520614e1e05326c13"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_val, batch_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f85bf3d7066088d44aa09490fcfab81a159f6c8b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
